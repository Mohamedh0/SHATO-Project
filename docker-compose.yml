version: "3.9"

services:
  # ----------------- LLM -----------------
  llm-service:
    build:
      context: ./llm-api
      args:
        HF_TOKEN: ${HF_TOKEN}   
    environment:
      HF_TOKEN: ${HF_TOKEN}     
    ports:
      - "8000:8000"

  # ----------------- Robot Validator -----------------
  robot-validator:
    build:
      context: ./robot-validator-api
    container_name: robot-validator
    ports:
      - "8001:8001"

  # ----------------- STT -----------------
  stt-service:
    build:
      context: ./stt-api
    container_name: stt-service
    ports:
      - "8002:8002"

  # ----------------- TTS -----------------
  tts-service:
    build:
      context: ./tts-api
    container_name: tts-service
    ports:
      - "8003:8003"

  # ----------------- Orchestrator -----------------
  orchestrator:
    build:
      context: ./orchestrator-api
    environment:
      stt_url: "http://stt-service:8002/transcribe"
      llm_url: "http://llm-service:8000/command"
      validator_url: "http://robot-validator:8001/execute_command"
      tts_url: "http://tts-service:8003/speak"
    ports:
      - "8500:8500"
    depends_on:
      - stt-service
      - llm-service
      - robot-validator
      - tts-service

  # ----------------- UI -----------------
  ui-service:
    build:
      context: ./ui-service
    ports:
      - "7860:7860"
    environment:
      ORCHESTRATOR_URL: "http://orchestrator:8500/voice_flow"
    depends_on:
      - orchestrator
