# LLM API Configuration
# Copy this file to .env and modify as needed

# Model Configuration
MODEL_NAME=microsoft/DialoGPT-medium
QUANTIZATION_ENABLED=true
VLLM_ENABLED=false

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
BATCH_SIZE=1

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Device Configuration
DEVICE=auto
# Options: auto, cpu, cuda, cuda:0, cuda:1, etc.

# Security
API_KEY_REQUIRED=false
RATE_LIMIT_PER_MINUTE=60

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090

# Cache Configuration
ENABLE_CACHE=false
CACHE_TTL=3600
REDIS_URL=redis://redis:6379/0

# Development
DEBUG=false
RELOAD=false
